{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from utils import get_random_wider_data\n",
    "from yolo3.model import face_yolo_body, yolo_loss, face_yolo_loss, preprocess_true_face_boxes\n",
    "from yolo3.utils import compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main():\n",
    "    log_dir = \"logs/000/\"\n",
    "    train_annotation_path = \"/home/text/ZHY/YOLO_face/dataset/wider_face_split/my_label.txt\"\n",
    "    val_annotation_path = \"/home/text/ZHY/YOLO_face/dataset/wider_face_split/wider_face_val_bbx_gt.txt\"\n",
    "    anchors_path = 'model_data/tiny_yolo_anchors.txt'\n",
    "    print(anchors_path)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "    input_shape = (288, 288)  # multiple of 32, hw\n",
    "    print('get it')\n",
    "    model = create_face_yolo_model(input_shape,anchors,freeze_body = 2)\n",
    "    print('get model')\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "                                 monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "\n",
    "    val_split = 0.1\n",
    "    with open(train_annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines) * val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 128\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_face_wrapper(lines[:num_train], batch_size, input_shape),\n",
    "                            steps_per_epoch=max(1, num_train // batch_size),\n",
    "                            validation_data=data_generator_face_wrapper(lines[num_train:], batch_size, input_shape),\n",
    "                            validation_steps=max(1, num_val // batch_size),\n",
    "                            epochs=50,\n",
    "                            initial_epoch=0,\n",
    "                            callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4),\n",
    "                      loss={'yolo_loss': lambda y_true, y_pred: y_pred})  # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 32  # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_face_wrapper(lines[:num_train], batch_size, input_shape),\n",
    "                            steps_per_epoch=max(1, num_train // batch_size),\n",
    "                            validation_data=data_generator_face_wrapper(lines[num_train:], batch_size, input_shape),\n",
    "                            validation_steps=max(1, num_val // batch_size),\n",
    "                            epochs=100,\n",
    "                            initial_epoch=50,\n",
    "                            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "        # Further training if needed.\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "def create_face_yolo_model(input_shape, anchors,load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    # calculate which grid that true ob belongs to   2 feature maps\n",
    "    # [[9 * 9 * 5], [18 * 18 * 5]]\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], 5)) for l in range(2)]\n",
    "    # y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l],num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = face_yolo_body(image_input)\n",
    "    # print('Create Tiny face YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "    model_loss = Lambda(face_yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_wider_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_face_boxes(box_data, input_shape)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_face_wrapper(annotation_lines, batch_size, input_shape):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
